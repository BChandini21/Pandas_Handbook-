{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa4c674-37f5-4f05-86ec-7b49ef2456e4",
   "metadata": {},
   "source": [
    "<b> Introduction to Pandas:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8e3efc-f6b2-42bd-a621-b0073d84c451",
   "metadata": {},
   "source": [
    "Pandas is a powerful data manipulation and analysis library for Python. The two primary data structures in Pandas are:\n",
    "\n",
    "<b>Series:</b> A one-dimensional labeled array capable of holding any data type. It is similar to a column in a table.\n",
    "\n",
    "<b>DataFrame:</b> A two-dimensional labeled data structure with columns of potentially different types. It can be thought of as a table or a spreadsheet.\n",
    "\n",
    "<b>Creating DataFrames and Series:</b>\n",
    "\n",
    "You can create DataFrames and Series from various data sources such as lists, dictionaries, and CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2947a1e1-9e05-4771-ae0f-709054f85111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series from list:\n",
      "0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "4    50\n",
      "dtype: int64\n",
      "\n",
      "DataFrame from dictionary:\n",
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a Series from a list\n",
    "list_data = [10, 20, 30, 40, 50]\n",
    "series = pd.Series(list_data)\n",
    "print(\"Series from list:\")\n",
    "print(series)\n",
    "\n",
    "# Creating a DataFrame from a dictionary\n",
    "dict_data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "             'Age': [25, 30, 35],\n",
    "             'City': ['New York', 'Los Angeles', 'Chicago']}\n",
    "df = pd.DataFrame(dict_data)\n",
    "print(\"\\nDataFrame from dictionary:\")\n",
    "print(df)\n",
    "\n",
    "# Reading a CSV file into a DataFrame\n",
    "# Uncomment the following lines if you have a CSV file to read\n",
    "# df_csv = pd.read_csv('path_to_file.csv')\n",
    "# print(\"\\nDataFrame from CSV file:\")\n",
    "# print(df_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605d5795-acb9-4bd9-881f-3d2a368ca492",
   "metadata": {},
   "source": [
    "<b>Common Operations:</b>\n",
    "\n",
    "<b>Selecting Data:</b>\n",
    "\n",
    "Selecting data refers to accessing specific rows or columns from a DataFrame. This can be done using labels (column names) or positions (row and column indices).\n",
    "\n",
    "<b>Selecting Columns:</b> You can select one or more columns by passing the column name(s) in square brackets.\n",
    "\n",
    "<b>Selecting Rows:</b> You can select rows using the loc and iloc accessors.\n",
    "\n",
    "loc: Access a group of rows and columns by labels or a boolean array.\n",
    "\n",
    "iloc: Access a group of rows and columns by integer position(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2fdbe58-92c9-4768-ab1e-9da2ccf006d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selecting the 'Name' column:\n",
      "0      Alice\n",
      "1        Bob\n",
      "2    Charlie\n",
      "Name: Name, dtype: object\n",
      "\n",
      "Selecting the 'Name' and 'City' columns:\n",
      "      Name         City\n",
      "0    Alice     New York\n",
      "1      Bob  Los Angeles\n",
      "2  Charlie      Chicago\n",
      "\n",
      "Selecting rows where index is 1 and 2 using loc:\n",
      "      Name  Age         City\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "\n",
      "Selecting the first two rows using iloc:\n",
      "    Name  Age         City\n",
      "0  Alice   25     New York\n",
      "1    Bob   30  Los Angeles\n"
     ]
    }
   ],
   "source": [
    "# Selecting a single column\n",
    "print(\"\\nSelecting the 'Name' column:\")\n",
    "print(df['Name'])\n",
    "\n",
    "# Selecting multiple columns\n",
    "print(\"\\nSelecting the 'Name' and 'City' columns:\")\n",
    "print(df[['Name', 'City']])\n",
    "\n",
    "# Selecting rows using loc\n",
    "print(\"\\nSelecting rows where index is 1 and 2 using loc:\")\n",
    "print(df.loc[1:2])\n",
    "\n",
    "# Selecting rows using iloc\n",
    "print(\"\\nSelecting the first two rows using iloc:\")\n",
    "print(df.iloc[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c21690-fad6-44bf-bdfe-cb4289881321",
   "metadata": {},
   "source": [
    "<b>Filtering Rows:</b>\n",
    "\n",
    "Filtering rows involves extracting rows that meet certain conditions. This is typically done using boolean indexing, where a boolean condition is applied to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ace108-b06d-427e-82a4-40c0eb2ffa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering rows where Age > 25:\n",
      "      Name  Age         City\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "\n",
      "Filtering rows where Age > 25 and City is 'Chicago':\n",
      "      Name  Age     City\n",
      "2  Charlie   35  Chicago\n"
     ]
    }
   ],
   "source": [
    "# Filtering rows where Age > 25\n",
    "print(\"\\nFiltering rows where Age > 25:\")\n",
    "print(df[df['Age'] > 25])\n",
    "\n",
    "# Filtering rows based on multiple conditions\n",
    "print(\"\\nFiltering rows where Age > 25 and City is 'Chicago':\")\n",
    "print(df[(df['Age'] > 25) & (df['City'] == 'Chicago')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b444f36-69a1-4015-9549-3c7a85f1ef7a",
   "metadata": {},
   "source": [
    "<b>Modifying Data:</b>\n",
    "\n",
    "Modifying data involves changing the values within the DataFrame. This can include updating individual values, adding new columns, or applying functions to columns.\n",
    "\n",
    "<b>Updating Values:</b> You can update individual values or entire columns using the loc or iloc accessors.\n",
    "\n",
    "<b>Adding Columns:</b> New columns can be added by simply assigning a Series or a list to a new column name.\n",
    "\n",
    "<b>Applying Functions:</b> Use the apply function to apply a function to each element in a column or row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe04f78b-aab9-4ab2-aabc-2f65b9cc4f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after modifying a single value:\n",
      "      Name  Age           City\n",
      "0    Alice   25       New York\n",
      "1      Bob   30  San Francisco\n",
      "2  Charlie   35        Chicago\n",
      "\n",
      "DataFrame after adding a new column:\n",
      "      Name  Age           City Country\n",
      "0    Alice   25       New York     USA\n",
      "1      Bob   30  San Francisco     USA\n",
      "2  Charlie   35        Chicago     USA\n",
      "\n",
      "DataFrame after applying a function to the 'Age' column:\n",
      "      Name  Age           City Country  Age_plus_10\n",
      "0    Alice   25       New York     USA           35\n",
      "1      Bob   30  San Francisco     USA           40\n",
      "2  Charlie   35        Chicago     USA           45\n"
     ]
    }
   ],
   "source": [
    "# Updating a single value\n",
    "df.loc[1, 'City'] = 'San Francisco'\n",
    "print(\"\\nDataFrame after modifying a single value:\")\n",
    "print(df)\n",
    "\n",
    "# Adding a new column\n",
    "df['Country'] = 'USA'\n",
    "print(\"\\nDataFrame after adding a new column:\")\n",
    "print(df)\n",
    "\n",
    "# Applying a function to a column\n",
    "df['Age_plus_10'] = df['Age'].apply(lambda x: x + 10)\n",
    "print(\"\\nDataFrame after applying a function to the 'Age' column:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d44d5-6d1c-4819-b26c-9d72330090e5",
   "metadata": {},
   "source": [
    "<b>Data Handling with Pandas:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62e1a54-91d4-420e-a123-f36a9c0219eb",
   "metadata": {},
   "source": [
    "<b>Reading Data from Files</b>\n",
    "\n",
    "Pandas can read data from various file formats, including CSV, Excel, and SQL databases. The most common format is CSV (Comma Separated Values), which stores tabular data in plain text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5ff0110-e7f5-4f21-a263-9d5092531178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a CSV file into a DataFrame\n",
    "# Uncomment the following lines if you have a CSV file to read\n",
    "# df_csv = pd.read_csv('path_to_file.csv')\n",
    "# print(\"DataFrame from CSV file:\")\n",
    "# print(df_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ccc5b8-15c3-474f-b372-2c1fa88ca308",
   "metadata": {},
   "source": [
    "<b>Handling Missing Data:</b>\n",
    "\n",
    "Handling missing data is a crucial step in data preprocessing. Missing data can cause issues in analysis and modeling. Pandas provides functions to handle missing values, remove duplicates, and convert data types.\n",
    "\n",
    "<b>Causes of Missing Data:</b>\n",
    "Missing data can occur due to various reasons, including:\n",
    "\n",
    "Errors in data collection or entry.\n",
    "\n",
    "Incomplete data sources.\n",
    "\n",
    "Data corruption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d99c73b-3cdd-480f-bccd-fe2264cb0998",
   "metadata": {},
   "source": [
    "<b>Identifying Missing Data:</b>\n",
    "\n",
    "You can identify missing data in a DataFrame using functions like isnull() and notnull(). These functions return a DataFrame of the same shape, but with Boolean values indicating the presence of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57aa0592-975a-4aed-9d25-fe5b8ec3d5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with missing values:\n",
      "     A    B  C\n",
      "0  1.0  4.0  7\n",
      "1  2.0  NaN  8\n",
      "2  NaN  6.0  9\n",
      "\n",
      "Checking for missing values:\n",
      "       A      B      C\n",
      "0  False  False  False\n",
      "1  False   True  False\n",
      "2   True  False  False\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame with missing values\n",
    "df_missing = pd.DataFrame({'A': [1, 2, None], 'B': [4, None, 6], 'C': [7, 8, 9]})\n",
    "print(\"\\nDataFrame with missing values:\")\n",
    "print(df_missing)\n",
    "\n",
    "# Checking for missing values\n",
    "print(\"\\nChecking for missing values:\")\n",
    "print(df_missing.isnull())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db23e568-7d2b-4dff-ba28-94c3ce991fb8",
   "metadata": {},
   "source": [
    "<b>Handling Missing Values:</b>\n",
    "\n",
    "There are several strategies for handling missing values:\n",
    "\n",
    "<b>Removing Missing Data:</b> Use dropna() to remove rows or columns with missing values.\n",
    "\n",
    "<b>Filling Missing Values:</b> Use fillna() to replace missing values with a specified value or method.\n",
    "\n",
    "<b>Imputation:</b> Use statistical methods to estimate and fill missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b959e8b-4aa3-4ba2-895e-3db9b73f40d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after dropping missing values:\n",
      "     A    B  C\n",
      "0  1.0  4.0  7\n",
      "\n",
      "DataFrame after filling missing values with 0:\n",
      "     A    B  C\n",
      "0  1.0  4.0  7\n",
      "1  2.0  0.0  8\n",
      "2  0.0  6.0  9\n",
      "\n",
      "DataFrame after forward fill:\n",
      "     A    B  C\n",
      "0  1.0  4.0  7\n",
      "1  2.0  4.0  8\n",
      "2  2.0  6.0  9\n",
      "\n",
      "DataFrame after backward fill:\n",
      "     A    B  C\n",
      "0  1.0  4.0  7\n",
      "1  2.0  6.0  8\n",
      "2  NaN  6.0  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cherani\\AppData\\Local\\Temp\\ipykernel_2548\\1767892460.py:12: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_missing_ffill = df_missing.fillna(method='ffill')\n",
      "C:\\Users\\Cherani\\AppData\\Local\\Temp\\ipykernel_2548\\1767892460.py:17: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_missing_bfill = df_missing.fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "# Removing rows with missing values\n",
    "df_missing_dropped = df_missing.dropna()\n",
    "print(\"\\nDataFrame after dropping missing values:\")\n",
    "print(df_missing_dropped)\n",
    "\n",
    "# Filling missing values with a specified value\n",
    "df_missing_filled = df_missing.fillna(0)\n",
    "print(\"\\nDataFrame after filling missing values with 0:\")\n",
    "print(df_missing_filled)\n",
    "\n",
    "# Forward fill (propagate last valid observation forward)\n",
    "df_missing_ffill = df_missing.fillna(method='ffill')\n",
    "print(\"\\nDataFrame after forward fill:\")\n",
    "print(df_missing_ffill)\n",
    "\n",
    "# Backward fill (propagate next valid observation backward)\n",
    "df_missing_bfill = df_missing.fillna(method='bfill')\n",
    "print(\"\\nDataFrame after backward fill:\")\n",
    "print(df_missing_bfill)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2249a120-c883-4284-9f78-5f4df136b9d3",
   "metadata": {},
   "source": [
    "<b>Removing Duplicates:</b>\n",
    "\n",
    "Duplicates can distort analysis and insights. Removing duplicates ensures data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "029e2ed1-1780-4817-ab45-d88729d8e7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame with duplicates:\n",
      "   A  B\n",
      "0  1  3\n",
      "1  1  3\n",
      "2  2  4\n",
      "\n",
      "DataFrame after removing duplicates:\n",
      "   A  B\n",
      "0  1  3\n",
      "2  2  4\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame with duplicates\n",
    "df_duplicates = pd.DataFrame({'A': [1, 1, 2], 'B': [3, 3, 4]})\n",
    "print(\"\\nDataFrame with duplicates:\")\n",
    "print(df_duplicates)\n",
    "\n",
    "# Removing duplicates\n",
    "df_no_duplicates = df_duplicates.drop_duplicates()\n",
    "print(\"\\nDataFrame after removing duplicates:\")\n",
    "print(df_no_duplicates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcee1d60-0a80-42a2-8919-9d6fbfb06e74",
   "metadata": {},
   "source": [
    "<b>Data Type Conversion:</b>\n",
    "\n",
    "Converting data types ensures consistency and allows for correct mathematical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01618c28-e4c2-4dd5-9a88-311c855a9c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after data type conversion:\n",
      "      Name   Age           City Country  Age_plus_10\n",
      "0    Alice  25.0       New York     USA           35\n",
      "1      Bob  30.0  San Francisco     USA           40\n",
      "2  Charlie  35.0        Chicago     USA           45\n"
     ]
    }
   ],
   "source": [
    "# Converting data types\n",
    "df['Age'] = df['Age'].astype(float)\n",
    "print(\"\\nDataFrame after data type conversion:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023c2c2-b3cd-4ad5-a746-3d4e72e0ba0a",
   "metadata": {},
   "source": [
    "<b>Data Analysis with Pandas:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e52a1d-6926-4df0-a444-76068abc0715",
   "metadata": {},
   "source": [
    "<b>Summary Statistics:</b>\n",
    "\n",
    "Pandas can generate descriptive statistics that summarize the central tendency, dispersion, and shape of a datasetâ€™s distribution. This includes functions like mean(), median(), std(), mode()\n",
    "\n",
    "<b>Mean:</b> Average value of the data.\n",
    "\n",
    "<b>Median:</b> Middle value of the data.\n",
    "\n",
    "<b>Mode:</b> Most frequently occurring value in the data.\n",
    "\n",
    "<b>Standard Deviation (std):</b> Measure of the amount of variation or dispersion.\n",
    "\n",
    "<b>Variance:</b> Measure of how much the data varies from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "427127e4-e25a-44db-a7a1-fb57187b3a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics of the original DataFrame:\n",
      "\n",
      "Additional statistics:\n",
      "Mean Age: 30.0\n",
      "Median Age: 30.0\n",
      "Standard Deviation of Age: 5.0\n",
      "Variance of Age: 25.0\n",
      "Mode of Age: [25. 30. 35.]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSummary statistics of the original DataFrame:\")\n",
    "# Additional statistics\n",
    "mean_age = df['Age'].mean()\n",
    "median_age = df['Age'].median()\n",
    "std_age = df['Age'].std()\n",
    "variance_age = df['Age'].var()\n",
    "mode_age = df['Age'].mode()\n",
    "\n",
    "print(\"\\nAdditional statistics:\")\n",
    "print(f\"Mean Age: {mean_age}\")\n",
    "print(f\"Median Age: {median_age}\")\n",
    "print(f\"Standard Deviation of Age: {std_age}\")\n",
    "print(f\"Variance of Age: {variance_age}\")\n",
    "print(f\"Mode of Age: {mode_age.values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3fd14c-5b1a-488d-8551-90746b803087",
   "metadata": {},
   "source": [
    "<b>Grouping Data and Aggregate Functions:</b>\n",
    "\n",
    "Grouping data and applying aggregate functions is a powerful feature in Pandas. It allows you to split your data into groups based on some criteria and then apply a function to each group. Common aggregate functions include mean(), sum(), count(), and max().\n",
    "\n",
    "<b>Grouping Data:</b>\n",
    "Grouping data involves splitting the data into subsets, applying a function to each subset, and combining the results into a DataFrame.\n",
    "\n",
    "<b>Grouping by a Single Column:</b> Use the groupby() function to group data by a single column.\n",
    "\n",
    "<b>Grouping by Multiple Columns:</b> Group data by multiple columns to get more detailed groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94682963-42b2-4e04-a46f-b72889e5763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean age by city:\n",
      "City\n",
      "Chicago          35.0\n",
      "New York         25.0\n",
      "San Francisco    30.0\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "Grouped DataFrame by 'City' and 'Age':\n",
      "                       Name Country  Age_plus_10\n",
      "City          Age                               \n",
      "Chicago       35.0  Charlie     USA           45\n",
      "New York      25.0    Alice     USA           35\n",
      "San Francisco 30.0      Bob     USA           40\n",
      "\n",
      "Count of entries by city:\n",
      "               Name  Age  Country  Age_plus_10\n",
      "City                                          \n",
      "Chicago           1    1        1            1\n",
      "New York          1    1        1            1\n",
      "San Francisco     1    1        1            1\n"
     ]
    }
   ],
   "source": [
    "# Grouping data by 'City' and calculating mean age\n",
    "grouped_df = df.groupby('City')['Age'].mean()\n",
    "print(\"\\nMean age by city:\")\n",
    "print(grouped_df)\n",
    "\n",
    "# Grouping by multiple columns and calculating sum\n",
    "df_grouped = df.groupby(['City', 'Age']).sum()\n",
    "print(\"\\nGrouped DataFrame by 'City' and 'Age':\")\n",
    "print(df_grouped)\n",
    "\n",
    "# Count the number of entries in each group\n",
    "df_grouped_count = df.groupby('City').count()\n",
    "print(\"\\nCount of entries by city:\")\n",
    "print(df_grouped_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d45b29-783b-4baa-b873-ecd80e1c5559",
   "metadata": {},
   "source": [
    "<b>Applying Aggregate Functions:</b>\n",
    "\n",
    "Aggregate functions can be applied to grouped data to summarize and analyze it. These functions include:\n",
    "\n",
    "<b>Mean (mean()):</b> Calculate the average value of each group.\n",
    "\n",
    "<b>Sum (sum()):</b> Calculate the sum of each group.\n",
    "\n",
    "<b>Count (count()):</b> Count the number of observations in each group.\n",
    "\n",
    "<b>Maximum (max()):</b> Find the maximum value in each group.\n",
    "\n",
    "<b>Minimum (min()):</b> Find the minimum value in each group.\n",
    "\n",
    "<b>Standard Deviation (std()):</b> Calculate the standard deviation of each group.\n",
    "\n",
    "<b>Variance (var()):</b> Calculate the variance of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11307bfa-c69c-4d9c-9c61-9495047b0b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grouped DataFrame with multiple aggregate functions:\n",
      "                Age                  Name\n",
      "               mean   max   min std count\n",
      "City                                     \n",
      "Chicago        35.0  35.0  35.0 NaN     1\n",
      "New York       25.0  25.0  25.0 NaN     1\n",
      "San Francisco  30.0  30.0  30.0 NaN     1\n",
      "\n",
      "Grouped DataFrame with renamed columns:\n",
      "               Mean Age  Max Age  Min Age  Age Std Dev  Name Count\n",
      "City                                                              \n",
      "Chicago            35.0     35.0     35.0          NaN           1\n",
      "New York           25.0     25.0     25.0          NaN           1\n",
      "San Francisco      30.0     30.0     30.0          NaN           1\n"
     ]
    }
   ],
   "source": [
    "# Applying multiple aggregate functions\n",
    "df_grouped_agg = df.groupby('City').agg({\n",
    "    'Age': ['mean', 'max', 'min', 'std'],\n",
    "    'Name': 'count'\n",
    "})\n",
    "print(\"\\nGrouped DataFrame with multiple aggregate functions:\")\n",
    "print(df_grouped_agg)\n",
    "\n",
    "# Renaming columns after aggregation\n",
    "df_grouped_agg.columns = ['Mean Age', 'Max Age', 'Min Age', 'Age Std Dev', 'Name Count']\n",
    "print(\"\\nGrouped DataFrame with renamed columns:\")\n",
    "print(df_grouped_agg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca73489-bec2-4632-b24a-2c3a6f0f603f",
   "metadata": {},
   "source": [
    "<b>Advanced Data Manipulation:</b>\n",
    "\n",
    "Advanced data manipulation techniques in Pandas include merging, joining, and concatenating DataFrames. These operations allow you to combine multiple DataFrames into a single DataFrame.\n",
    "\n",
    "<b>Merging:</b> Combine two DataFrames based on a key column using pd.merge().\n",
    "\n",
    "<b>Joining:</b> Join DataFrames using their indexes with join().\n",
    "\n",
    "<b>Concatenating:</b> Append DataFrames vertically or horizontally using pd.concat().\n",
    "\n",
    "<b>Merging DataFrames:</b>\n",
    "Merging is similar to SQL joins and is used to combine DataFrames on a key column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dc6e0e3-4d28-4cb3-a801-e3fa632b65aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged DataFrame (inner join):\n",
      "  Key  Value1  Value2\n",
      "0   A       1       4\n",
      "1   B       2       5\n",
      "\n",
      "Merged DataFrame (outer join):\n",
      "  Key  Value1  Value2\n",
      "0   A     1.0     4.0\n",
      "1   B     2.0     5.0\n",
      "2   C     3.0     NaN\n",
      "3   D     NaN     6.0\n"
     ]
    }
   ],
   "source": [
    "# Merging DataFrames\n",
    "df1 = pd.DataFrame({'Key': ['A', 'B', 'C'], 'Value1': [1, 2, 3]})\n",
    "df2 = pd.DataFrame({'Key': ['A', 'B', 'D'], 'Value2': [4, 5, 6]})\n",
    "merged_df = pd.merge(df1, df2, on='Key', how='inner')\n",
    "print(\"\\nMerged DataFrame (inner join):\")\n",
    "print(merged_df)\n",
    "\n",
    "# Outer merge\n",
    "merged_df_outer = pd.merge(df1, df2, on='Key', how='outer')\n",
    "print(\"\\nMerged DataFrame (outer join):\")\n",
    "print(merged_df_outer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7228c2-9013-4aa0-a2bf-b11be77e19c4",
   "metadata": {},
   "source": [
    "<b>Concatenating DataFrames:</b>\n",
    "\n",
    "Concatenation is used to append DataFrames either vertically (axis=0) or horizontally (axis=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d5711b0-f126-401f-af28-aa98b09cfdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concatenated DataFrame (vertical):\n",
      "  Key  Value1  Value2\n",
      "0   A     1.0     NaN\n",
      "1   B     2.0     NaN\n",
      "2   C     3.0     NaN\n",
      "0   A     NaN     4.0\n",
      "1   B     NaN     5.0\n",
      "2   D     NaN     6.0\n",
      "\n",
      "Concatenated DataFrame (horizontal):\n",
      "  Key  Value1 Key  Value2\n",
      "0   A       1   A       4\n",
      "1   B       2   B       5\n",
      "2   C       3   D       6\n"
     ]
    }
   ],
   "source": [
    "# Concatenating DataFrames vertically\n",
    "concat_df_vertical = pd.concat([df1, df2], axis=0)\n",
    "print(\"\\nConcatenated DataFrame (vertical):\")\n",
    "print(concat_df_vertical)\n",
    "\n",
    "# Concatenating DataFrames horizontally\n",
    "concat_df_horizontal = pd.concat([df1, df2], axis=1)\n",
    "print(\"\\nConcatenated DataFrame (horizontal):\")\n",
    "print(concat_df_horizontal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c92172-82aa-4d06-b20b-8f52add168a7",
   "metadata": {},
   "source": [
    "<b>Application in Data Science:</b>\n",
    "\n",
    "<b>Advantages of Using Pandas:</b>\n",
    "Pandas is a powerful and flexible data manipulation library that offers several advantages over traditional Python data structures:\n",
    "\n",
    "<b>Ease of Use:</b> Intuitive API and powerful functions for data manipulation and analysis.\n",
    "\n",
    "<b>Performance:</b> Built on top of NumPy, providing fast and efficient operations on large datasets.\n",
    "\n",
    "<b>Data Handling:</b> Ability to handle missing data, duplicates, and data type conversions.\n",
    "\n",
    "<b>Integration:</b> Easily integrates with other data science libraries such as NumPy, Matplotlib, and Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b0872c-2322-4b11-bb67-39d25bfbec2b",
   "metadata": {},
   "source": [
    "<b>Real-World Applications:</b>\n",
    "\n",
    "Pandas is essential in various real-world data science applications, including:\n",
    "\n",
    "<b>Data Cleaning:</b> Preprocessing raw data to remove inconsistencies and prepare it for analysis.\n",
    "\n",
    "<b>Exploratory Data Analysis (EDA):</b> Summarizing and visualizing data to uncover patterns and insights.\n",
    "\n",
    "<b>Data Transformation:</b> Reshaping and transforming data for analysis and modeling.\n",
    "\n",
    "<b>Time Series Analysis:</b> Handling and analyzing time series data for trends and patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81e3ae1-90c8-408d-8d30-d9668ced0850",
   "metadata": {},
   "source": [
    "Example: Data Cleaning:\n",
    "\n",
    "Pandas is widely used for data cleaning, which involves handling missing values, removing duplicates, and correcting data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0281c26-42c9-43a9-99eb-dc09e253bdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned DataFrame:\n",
      "      Name   Age         City\n",
      "0    Alice  25.0     New York\n",
      "1      Bob  30.0  Los Angeles\n",
      "2  Charlie  35.0      Chicago\n",
      "3      Bob  30.0      Unknown\n"
     ]
    }
   ],
   "source": [
    "# Example DataFrame with messy data\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'Bob'],\n",
    "        'Age': [25, None, 35, 30],\n",
    "        'City': ['New York', 'Los Angeles', 'Chicago', None]}\n",
    "df_messy = pd.DataFrame(data)\n",
    "\n",
    "# Handling missing values\n",
    "df_messy['Age'] = df_messy['Age'].fillna(df_messy['Age'].mean())\n",
    "df_messy['City'] = df_messy['City'].fillna('Unknown')\n",
    "\n",
    "# Removing duplicates\n",
    "df_clean = df_messy.drop_duplicates()\n",
    "\n",
    "print(\"\\nCleaned DataFrame:\")\n",
    "print(df_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539b5eeb-b615-4316-9e77-8602eee7503c",
   "metadata": {},
   "source": [
    "Example: Exploratory Data Analysis (EDA):\n",
    "\n",
    "EDA involves generating summary statistics and visualizing data to uncover patterns and insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34a6017b-3352-495b-adc8-7e94f6566ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics of the cleaned DataFrame:\n",
      "             Age\n",
      "count   4.000000\n",
      "mean   30.000000\n",
      "std     4.082483\n",
      "min    25.000000\n",
      "25%    28.750000\n",
      "50%    30.000000\n",
      "75%    31.250000\n",
      "max    35.000000\n"
     ]
    }
   ],
   "source": [
    "# Generating summary statistics\n",
    "print(\"\\nSummary statistics of the cleaned DataFrame:\")\n",
    "print(df_clean.describe())\n",
    "\n",
    "# Visualizing data (requires Matplotlib or Seaborn)\n",
    "# import matplotlib.pyplot as plt\n",
    "# df_clean['Age'].plot(kind='hist', title='Age Distribution')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e3ec2-3b9f-446e-b81e-b5f0d0efad4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
